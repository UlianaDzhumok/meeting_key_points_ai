{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "collapsed_sections": [
        "VyGfzJzTbpzy"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка"
      ],
      "metadata": {
        "id": "is2WNnonbiue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Подключение хранилища"
      ],
      "metadata": {
        "id": "d0BZ_ciXbm3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwC5zUpTWwKh",
        "outputId": "1069a2dd-b912-4753-aa4b-a7b7cc77d9bb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Установка зависимостей"
      ],
      "metadata": {
        "id": "VyGfzJzTbpzy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --no-deps bitsandbytes accelerate xformers==0.0.27.post2 peft trl triton==3.1.0\n",
        "!pip install --no-deps cut_cross_entropy unsloth_zoo\n",
        "!pip install sentencepiece protobuf datasets huggingface_hub hf_transfer openai-whisper soundfile librosa\n",
        "!pip install --no-deps unsloth ffmpeg\n",
        "!pip install flash-attn --no-build-isolation --no-cache-dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KqcvTvZdWygt",
        "outputId": "0f45d545-7f2f-4bfe-d445-daaf78a6a42c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Collecting xformers==0.0.27.post2\n",
            "  Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Collecting trl\n",
            "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (3.1.0)\n",
            "Downloading xformers-0.0.27.post2-cp311-cp311-manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.3-py3-none-manylinux_2_24_x86_64.whl (76.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xformers, trl, bitsandbytes\n",
            "Successfully installed bitsandbytes-0.45.3 trl-0.15.2 xformers-0.0.27.post2\n",
            "Collecting cut_cross_entropy\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting unsloth_zoo\n",
            "  Downloading unsloth_zoo-2025.3.2-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading unsloth_zoo-2025.3.2-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unsloth_zoo, cut_cross_entropy\n",
            "Successfully installed cut_cross_entropy-25.1.1 unsloth_zoo-2025.3.2\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (4.25.6)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.28.1)\n",
            "Collecting hf_transfer\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting openai-whisper\n",
            "  Downloading openai-whisper-20240930.tar.gz (800 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m800.5/800.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.11/dist-packages (0.13.1)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.11/dist-packages (0.10.2.post1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.10.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (0.61.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (2.5.1+cu124)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (10.6.0)\n",
            "Collecting tiktoken (from openai-whisper)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from openai-whisper) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile) (1.17.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.11/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.6.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.11/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.11/dist-packages (from librosa) (1.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile) (2.22)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba->openai-whisper) (0.44.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->openai-whisper)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->openai-whisper)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->openai-whisper)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->openai-whisper) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n",
            "Downloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.4/485.4 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803373 sha256=3f95263382bcc8db8b7adf1526aaa1c0bc48c89242cc9bbece571aa03d85da95\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/f2/ce/6eb23db4091d026238ce76703bd66da60b969d70bcc81d5d3a\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf_transfer, dill, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets, openai-whisper\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "unsloth-zoo 2025.3.2 requires tyro, which is not installed.\n",
            "unsloth-zoo 2025.3.2 requires protobuf<4.0.0, but you have protobuf 4.25.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.3.2 dill-0.3.8 hf_transfer-0.1.9 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 openai-whisper-20240930 tiktoken-0.9.0 xxhash-3.5.0\n",
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.3.4-py3-none-any.whl.metadata (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.2/59.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpeg\n",
            "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading unsloth-2025.3.4-py3-none-any.whl (190 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.8/190.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
            "  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=eb77d6095bc9723a3359f373a360a88b07b9f34ed3b7b4d32d7e5726cedbf051\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/30/c5/576bdd729f3bc062d62a551be7fefd6ed2f761901568171e4e\n",
            "Successfully built ffmpeg\n",
            "Installing collected packages: ffmpeg, unsloth\n",
            "Successfully installed ffmpeg-1.4 unsloth-2025.3.4\n",
            "Collecting flash-attn\n",
            "  Downloading flash_attn-2.7.4.post1.tar.gz (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from flash-attn) (2.5.1+cu124)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->flash-attn) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->flash-attn) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->flash-attn) (3.0.2)\n",
            "Building wheels for collected packages: flash-attn\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.4.post1-cp311-cp311-linux_x86_64.whl size=187815463 sha256=d944fc7d2f962bce83fc4708c2fc0c21eaf8255962a0b350ae919362a51b7ef2\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rafqodw_/wheels/3d/88/d8/284b89f56af7d5bf366b10d6b8e251ac8a7c7bf3f04203fb4f\n",
            "Successfully built flash-attn\n",
            "Installing collected packages: flash-attn\n",
            "Successfully installed flash-attn-2.7.4.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Сервисные функции"
      ],
      "metadata": {
        "id": "AqoDRf6Nb158"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция выделения аудио из видео файла"
      ],
      "metadata": {
        "id": "TyX7hjdNWAra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "\n",
        "def extract_audio(video_path):\n",
        "  audio_path = \"/content/drive/MyDrive/DP_outputs/extracted_audio.wav\"\n",
        "\n",
        "  subprocess.run([\n",
        "      \"ffmpeg\", \"-i\", video_path, \"-acodec\", \"pcm_s16le\", \"-ar\", \"16000\", audio_path, \"-y\"\n",
        "  ])\n",
        "\n",
        "  print(\"Аудио успешно извлечено:\", audio_path)\n",
        "  return audio_path"
      ],
      "metadata": {
        "id": "riMWEFHxWACn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция разбиения аудио на части"
      ],
      "metadata": {
        "id": "s2FFjQXXVbt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import soundfile as sf\n",
        "import os\n",
        "\n",
        "def split_audio(audio_path):\n",
        "  # Load full audio file\n",
        "  chunks_path=\"/content/drive/MyDrive/DP_outputs/chunks\"\n",
        "  os.mkdir(chunks_path)\n",
        "  audio, sr = librosa.load(audio_path, sr=16000)  # Ensure 16kHz\n",
        "  chunk_duration = 30  # Split into 30-second chunks\n",
        "  chunk_samples = chunk_duration * sr  # Number of samples per chunk\n",
        "\n",
        "  # Create chunks\n",
        "  chunks = [audio[i : i + chunk_samples] for i in range(0, len(audio), chunk_samples)]\n",
        "\n",
        "  # Save chunks as individual WAV files\n",
        "  chunk_paths = []\n",
        "  for i, chunk in enumerate(chunks):\n",
        "      chunk_file = f\"{chunks_path}/audio_chunk_{i}.wav\"\n",
        "      sf.write(chunk_file, chunk, sr)\n",
        "      chunk_paths.append(chunk_file)\n",
        "\n",
        "  print(f\"Аудио разделено на {len(chunk_paths)} частей.\")\n",
        "\n",
        "  return chunk_paths"
      ],
      "metadata": {
        "id": "nAjnltI2VbKV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция транскрибации"
      ],
      "metadata": {
        "id": "sbWcNso8Wmnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import gc\n",
        "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
        "from tqdm import tqdm\n",
        "\n",
        "class LoRALayer(nn.Module):\n",
        "    \"\"\"Basic LoRA implementation for Linear layers.\"\"\"\n",
        "    def __init__(self, base_layer, r=8, alpha=32, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.base_layer = base_layer  # Original layer\n",
        "        self.r = r  # Rank\n",
        "        self.scaling = alpha / r\n",
        "\n",
        "        # LoRA A and B matrices\n",
        "        self.lora_A = nn.Linear(base_layer.in_features, r, bias=False)\n",
        "        self.lora_B = nn.Linear(r, base_layer.out_features, bias=False)\n",
        "\n",
        "         # Dropout between A and B\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Initialize LoRA weights\n",
        "        nn.init.kaiming_uniform_(self.lora_A.weight)\n",
        "        nn.init.zeros_(self.lora_B.weight)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.base_layer(x) + self.lora_B(self.lora_A(x)) * self.scaling\n",
        "\n",
        "def get_transcription(chunk_paths):\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model_path=\"/content/drive/MyDrive/DP_models/final/whisper-finetuned-ru\"\n",
        "  model_name=\"openai/whisper-small\"\n",
        "\n",
        "  # Загружаем процессор и базовую модель Whisper\n",
        "  processor = WhisperProcessor.from_pretrained(model_name)\n",
        "  whisper_model = WhisperForConditionalGeneration.from_pretrained(model_name).to(device)\n",
        "\n",
        "  # Принудительное использование русского языка для декодера\n",
        "  whisper_model.config.forced_decoder_ids = processor.get_decoder_prompt_ids(language=\"russian\", task=\"transcribe\")\n",
        "\n",
        "  # Отключаем dropout перед инференсом\n",
        "  for name, module in whisper_model.named_modules():\n",
        "      if isinstance(module, nn.Linear) and any(k in name for k in [\"q_proj\", \"v_proj\", \"k_proj\", \"out_proj\", \"fc1\", \"fc2\"]):\n",
        "          parent = whisper_model.get_submodule(\".\".join(name.split(\".\")[:-1]))\n",
        "          lora_layer = LoRALayer(module, r=16, alpha=32, dropout=0.4).to(device)\n",
        "          setattr(parent, name.split(\".\")[-1], lora_layer)\n",
        "\n",
        "  # Загружаем веса LoRA и конвертируем их в FP16\n",
        "  lora_weights = torch.load(model_path + \"/whisper_lora_weights.pth\", map_location=device)\n",
        "  for k, v in lora_weights.items():\n",
        "      lora_weights[k] = v.half()  # Преобразуем в FP16\n",
        "\n",
        "  # Загружаем LoRA веса в модель\n",
        "  missing_keys, unexpected_keys = whisper_model.load_state_dict(lora_weights, strict=False)\n",
        "  print(\"LoRA веса загружены.\")\n",
        "  print(f\"Пропущенные ключи: {missing_keys}\")\n",
        "  print(f\"Неожиданные ключи: {unexpected_keys}\")\n",
        "\n",
        "  # Переводим в режим инференса и полностью отключаем dropout\n",
        "  whisper_model.eval()\n",
        "  for name, module in whisper_model.named_modules():\n",
        "      if isinstance(module, nn.Dropout):\n",
        "          module.p = 0.0  # Полностью отключаем dropout\n",
        "\n",
        "  # Применяем torch.compile() для ускорения (если поддерживается)\n",
        "  try:\n",
        "      whisper_model = torch.compile(whisper_model)\n",
        "      print(\"torch.compile() успешно применён для ускорения инференса!\")\n",
        "  except AttributeError:\n",
        "      print(\"torch.compile() не поддерживается в данной версии PyTorch, пропускаем...\")\n",
        "\n",
        "  # Transcribe each chunk\n",
        "  transcriptions = []\n",
        "\n",
        "  # Assuming chunk_paths is a list of audio chunk file paths\n",
        "  for chunk_file in tqdm(chunk_paths, desc=\"Обработка частей\", unit=\"chunk\"):\n",
        "      # Load audio (must be 16kHz for Whisper)\n",
        "      audio, _ = librosa.load(chunk_file, sr=16000)\n",
        "\n",
        "      # Tokenize input for Whisper\n",
        "      input_features = processor(audio, sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
        "\n",
        "      # Transcribe\n",
        "      with torch.no_grad():\n",
        "          predicted_ids = whisper_model.generate(input_features)\n",
        "\n",
        "      transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)[0]\n",
        "      transcriptions.append(transcription)\n",
        "\n",
        "  # Combine all transcriptions\n",
        "  full_transcription = \" \".join(transcriptions)\n",
        "\n",
        "  del whisper_model\n",
        "  del processor\n",
        "  del transcriptions\n",
        "  del transcription\n",
        "  del chunk_file\n",
        "  del audio\n",
        "  del input_features\n",
        "\n",
        "  # Delete all variables that might hold tensors\n",
        "  for obj in gc.get_objects():\n",
        "      try:\n",
        "          if torch.is_tensor(obj) or (hasattr(obj, \"data\") and torch.is_tensor(obj.data)):\n",
        "              del obj\n",
        "      except:\n",
        "          pass\n",
        "\n",
        "  gc.collect()  # Force garbage collection\n",
        "  torch.cuda.empty_cache()  # Free GPU memory\n",
        "  torch.cuda.ipc_collect()  # Collect GPU shared memory\n",
        "\n",
        "  return full_transcription"
      ],
      "metadata": {
        "id": "GwwY00ZdWqKE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функции обработки текста"
      ],
      "metadata": {
        "id": "NG-f-fyvmYJf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from deepmultilingualpunctuation import PunctuationModel\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "def clean_transcript(input_text):\n",
        "    \"\"\"Очищает транскрипцию и разбивает на осмысленные предложения.\"\"\"\n",
        "\n",
        "    # 1. Удаляем бессмысленные фразы и шум\n",
        "    common_phrases = [\n",
        "    r\"\\bсбер какие\\b\", r\"\\bджой какие\\b\", r\"\\bафина какие\\b\", r\"\\bтихо\\b\",\n",
        "    r\"\\bкакие деньги\\b\", r\"\\bкакие вопросы\\b\", r\"\\bкакие виды\\b\",\n",
        "    r\"\\bкакие расклады\\b\", r\"\\bкакие правила\\b\", r\"\\bкакие кредиты\\b\",\n",
        "    r\"\\bкакие платежные\\b\", r\"\\bкакие планы\\b\", r\"\\bкакие условия\\b\",\n",
        "    r\"\\bкакие виды у фильма\\b\", r\"\\bкакие виды у города\\b\",\n",
        "    r\"\\bкакие виды у банка\\b\", r\"\\bкакие вопросы мне нужны\\b\",\n",
        "    r\"\\bкакие поечару\\b\", r\"\\bкакие как там\\b\", r\"\\bкакие у города\\b\",\n",
        "    r\"\\bкакие какие\\b\", r\"\\bкакие виды говорить\\b\", r\"\\bкакие что делать\\b\",\n",
        "    r\"\\bпожалуйста\\b\", r\"\\bтихо\\b\", r\"\\bафина\\b\", r\"\\bджой\\b\",\n",
        "    r\"\\bменьше часов по работе\\b\", r\"\\bвопросы у моей семьи\\b\",\n",
        "    r\"\\bбудем оттуда\\b\", r\"\\bбудем менять тогда\\b\", r\"\\bпродолжилась там же\\b\",\n",
        "    r\"\\bсчетом объема\\b\", r\"\\bкуда же вы\\b\", r\"\\bкуда идем\\b\",\n",
        "    r\"\\bгромче если можно\\b\", r\"\\bкак называется\\b\", r\"\\bэто тоже важно\\b\",\n",
        "    r\"\\bработаем не работаем\\b\", r\"\\bэто понятно здесь\\b\", r\"\\bчто нам нужно\\b\",\n",
        "    r\"\\bпосмотреть афина\\b\", r\"\\bпосмотреть как бы\\b\", r\"\\bпосмотреть пробуем\\b\",\n",
        "    r\"\\bкуда перейдем\\b\", r\"\\bну то есть\\b\", r\"\\bто есть\\b\", r\"\\bи уже от этого\\b\",\n",
        "    r\"\\bвиды у фильма\\b\", r\"\\bвиды \\b\",r\"\\bафина\\b\", r\"\\bджой\\b\",r\"\\bсбер\\b\",\n",
        "    r\"\\bсалют среднее расстояние между нептуном и солнцем\\b\", r\"\\bсалют\\b\"]\n",
        "\n",
        "    for phrase in common_phrases:\n",
        "        input_text = re.sub(phrase, \"\", input_text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 2. Убираем повторы слов (например, \"финансист финансист\" → \"финансист\")\n",
        "    input_text = re.sub(r\"\\b(\\w+)\\s+\\1\\b\", r\"\\1\", input_text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 3. Убираем длинные повторяющиеся буквы (например, \"ээээ\" → \"э\")\n",
        "    input_text = re.sub(r\"([a-zA-Zа-яА-Я])\\1{3,}\", r\"\\1\", input_text)\n",
        "\n",
        "    # 4. Разбиваем текст на предложения\n",
        "    sentences = sent_tokenize(input_text)\n",
        "\n",
        "    # 5. Фильтруем слишком короткие и бессмысленные предложения\n",
        "    sentences = [sent for sent in sentences if len(sent.split()) > 3]\n",
        "\n",
        "    # 6. Убираем случайные цифры, стоящие отдельно (например, \"два три 9\" → \"два три\")\n",
        "    sentences = [re.sub(r\"\\b\\d+\\b\", \"\", sent) for sent in sentences]\n",
        "\n",
        "    # 7. Объединяем обратно в текст\n",
        "    cleaned_text = \" \".join(sentences)\n",
        "\n",
        "    return cleaned_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTahTviomaxR",
        "outputId": "7eda3297-4003-41d7-ce55-461b667399b5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция выделения ключевой информации из транскрипции"
      ],
      "metadata": {
        "id": "LLqRiHO8ZISK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import unsloth\n",
        "from unsloth import FastLanguageModel\n",
        "from unsloth import is_bfloat16_supported\n",
        "import torch\n",
        "import gc\n",
        "import json\n",
        "import re\n",
        "import time\n",
        "import ast\n",
        "from tqdm import tqdm\n",
        "from pydantic import BaseModel, ValidationError\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define structured output format using Pydantic\n",
        "class MeetingSummary(BaseModel):\n",
        "    Summarization: str\n",
        "    Topics: list[str]\n",
        "    Actions: list[str]\n",
        "    Problems: list[str]\n",
        "    Decisions: list[str]\n",
        "\n",
        "\n",
        "# Шаблон JSON\n",
        "REFERENCE_JSON = {\n",
        "    \"Summarization\": \"Brief meeting summary...\",\n",
        "    \"Topics\": [\"Topic 1\", \"Topic 2\"],\n",
        "    \"Actions\": [\"Action 1\", \"Action 2\"],\n",
        "    \"Problems\": [\"Problem 1\", \"Problem 2\"],\n",
        "    \"Decisions\": [\"Decision 1\", \"Decision 2\"]\n",
        "}\n",
        "\n",
        "# Фиксированный промпт без транскрипта\n",
        "PROMPT_TEMPLATE = \"\"\"\\\n",
        "Analyze the following meeting transcript and extract the key points:\n",
        "1. **Summarization** – a brief summary of the meeting.\n",
        "2. **Topics** – a list of topics discussed.\n",
        "3. **Decisions** – key decisions made.\n",
        "4. **Problems** – challenges or issues identified.\n",
        "5. **Actions** – planned or taken actions.\n",
        "\n",
        "Return the output **STRICTLY in the following JSON format**:\n",
        "{{\n",
        "  \"Summarization\": \"Brief meeting summary...\",\n",
        "  \"Topics\": [\"Topic 1\", \"Topic 2\"],\n",
        "  \"Actions\": [\"Action 1\", \"Action 2\"],\n",
        "  \"Problems\": [\"Problem 1\", \"Problem 2\"],\n",
        "  \"Decisions\": [\"Decision 1\", \"Decision 2\"]\n",
        "}}\n",
        "\n",
        "Meeting transcript (in Russian):\n",
        "{transcript}\n",
        "\n",
        "**Return only a valid JSON response in Russian language.**\n",
        "**Do not include explanations, introductions, or extra text.**\n",
        "**If a category is missing, return an empty array [].**\n",
        "\n",
        "### Response:\n",
        "\"\"\"\n",
        "\n",
        "def clean_json_fields(data):\n",
        "    \"\"\"Очищает JSON, исправляя списки, если они закодированы как строки.\"\"\"\n",
        "    for key in [\"Topics\", \"Actions\", \"Problems\", \"Decisions\"]:\n",
        "        if isinstance(data.get(key), list):\n",
        "            cleaned_list = []\n",
        "            for item in data[key]:\n",
        "                if isinstance(item, str) and item.startswith(\"[\"):\n",
        "                    try:\n",
        "                        cleaned_list.extend(ast.literal_eval(item))  # Разворачиваем вложенные списки\n",
        "                    except (SyntaxError, ValueError):\n",
        "                        cleaned_list.append(item)  # Если ошибка, оставляем как есть\n",
        "                else:\n",
        "                    cleaned_list.append(item)\n",
        "            data[key] = cleaned_list  # Обновляем JSON-объект\n",
        "    return data\n",
        "\n",
        "def extract_valid_json(text):\n",
        "    \"\"\"Извлекает первый JSON, отличный от шаблона.\"\"\"\n",
        "    text = text.strip()\n",
        "\n",
        "    # Убираем \"### Response:\" и \"Response:\", если они есть\n",
        "    text = re.sub(r\"^### Response:\\s*\", \"\", text)\n",
        "    text = re.sub(r\"^Response:\\s*\", \"\", text)\n",
        "\n",
        "    # Находим **все** JSON-блоки в тексте\n",
        "    json_matches = re.findall(r\"\\{[\\s\\S]*?\\}\", text)\n",
        "\n",
        "    for json_text in json_matches:\n",
        "        try:\n",
        "            # Пробуем загрузить как JSON\n",
        "            extracted_json = json.loads(json_text)\n",
        "        except json.JSONDecodeError:\n",
        "            try:\n",
        "                extracted_json = ast.literal_eval(json_text)  # Пробуем как Python-словарь\n",
        "            except (ValueError, SyntaxError):\n",
        "                continue  # Если ошибка, пропускаем этот JSON\n",
        "\n",
        "        # Чистим JSON от вложенных строковых списков\n",
        "        extracted_json = clean_json_fields(extracted_json)\n",
        "\n",
        "        # Если JSON **отличается от шаблона**, возвращаем его\n",
        "        if extracted_json and extracted_json != REFERENCE_JSON:\n",
        "            return extracted_json\n",
        "\n",
        "    return None  # Если не найдено отличного JSON\n",
        "\n",
        "# Функция разбивает только текст транскрипта\n",
        "def split_transcript(tokenizer, transcript, max_tokens=3000, overlap=300):\n",
        "    tokens = tokenizer.tokenize(transcript)\n",
        "    chunks = []\n",
        "    start = 0\n",
        "\n",
        "    while start < len(tokens):\n",
        "        end = min(start + max_tokens, len(tokens))\n",
        "        chunk = tokenizer.convert_tokens_to_string(tokens[start:end])\n",
        "        chunks.append(chunk)\n",
        "        start += max_tokens - overlap  # Overlapping context\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Функция для генерации ответа\n",
        "def generate_response(model, tokenizer, chunk: str) -> str:\n",
        "    prompt = PROMPT_TEMPLATE.format(transcript=chunk)  # Вставляем только транскрипт\n",
        "    inputs = tokenizer([prompt], return_tensors=\"pt\", truncation=True, max_length=4096).to(device)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=200, do_sample=False)\n",
        "\n",
        "    response = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Функция обработки чанка\n",
        "def summarize_chunk(model, tokenizer, chunk):\n",
        "    response = generate_response(model, tokenizer, chunk)\n",
        "    #print(\"Response:\\n\", response)\n",
        "\n",
        "    json_data = extract_valid_json(response)\n",
        "    #print(\"JSON:\\n\", json_data)\n",
        "    return json_data if json_data else {}  # Если JSON не найден, вернем {}\n",
        "\n",
        "def merge_chunks(chunks):\n",
        "    \"\"\"Объединяет JSON-резюме всех чанков в один итоговый JSON.\"\"\"\n",
        "    if not chunks:\n",
        "        return {\n",
        "            \"Summarization\": \"\",\n",
        "            \"Topics\": [],\n",
        "            \"Actions\": [],\n",
        "            \"Problems\": [],\n",
        "            \"Decisions\": []\n",
        "        }  # Возвращаем пустую структуру, если нет чанков\n",
        "\n",
        "    merged_summary = \" \".join(chunk.get(\"Summarization\", \"\") for chunk in chunks)\n",
        "\n",
        "    merged_topics = list(set(topic for chunk in chunks for topic in chunk.get(\"Topics\", [])))\n",
        "    merged_actions = list(set(action for chunk in chunks for action in chunk.get(\"Actions\", [])))\n",
        "    merged_problems = list(set(problem for chunk in chunks for problem in chunk.get(\"Problems\", [])))\n",
        "    merged_decisions = list(set(decision for chunk in chunks for decision in chunk.get(\"Decisions\", [])))\n",
        "\n",
        "    return {\n",
        "        \"Summarization\": merged_summary,\n",
        "        \"Topics\": merged_topics,\n",
        "        \"Actions\": merged_actions,\n",
        "        \"Problems\": merged_problems,\n",
        "        \"Decisions\": merged_decisions,\n",
        "    }\n",
        "\n",
        "# Главная функция обработки встречи\n",
        "def extract_meeting_summary(model, tokenizer, input_text: str, retry_attempts=3):\n",
        "    attempts = 0\n",
        "    while attempts < retry_attempts:\n",
        "        chunks = split_transcript(tokenizer, input_text)  # Разбиваем только транскрипт\n",
        "        chunk_summaries = []\n",
        "\n",
        "        # Обрабатываем каждый чанк отдельно\n",
        "        for chunk in chunks:\n",
        "            summary = summarize_chunk(model, tokenizer, chunk)\n",
        "            if summary:  # Если есть данные, добавляем\n",
        "                chunk_summaries.append(summary)\n",
        "\n",
        "        #print(chunk_summaries)\n",
        "        # Проверяем, есть ли успешные JSON-ответы\n",
        "        if not chunk_summaries:\n",
        "            print(f\"Ошибка: все чанки пустые после {retry_attempts} попыток!\")\n",
        "            return {  # Если все чанки пустые, возвращаем пустую структуру\n",
        "                        \"Summarization\": \"\",\n",
        "                        \"Topics\": [],\n",
        "                        \"Actions\": [],\n",
        "                        \"Problems\": [],\n",
        "                        \"Decisions\": []\n",
        "                    }\n",
        "\n",
        "        # Объединяем все чанки\n",
        "        final_summary = merge_chunks(chunk_summaries)\n",
        "        return final_summary\n",
        "\n",
        "def get_meeting_info(input_text):\n",
        "    # Очищаем транскрипт (если clean_transcript() нужна, добавь её)\n",
        "    cleaned_text = input_text  # Удали это, если используешь clean_transcript(input_text)\n",
        "\n",
        "    deepseek_model_path = \"/content/drive/MyDrive/DP_models/final/unsloth_deepseek_r1_finetuned_16K/checkpoint-401\"\n",
        "    max_seq_length=16_384\n",
        "    max_new_tokens=2000\n",
        "\n",
        "    deepseek_model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = deepseek_model_path,\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = None,\n",
        "        load_in_4bit = True,\n",
        "        device_map = 'auto',\n",
        "        trust_remote_code=True\n",
        "        )\n",
        "\n",
        "    deepseek_model=FastLanguageModel.for_inference(deepseek_model)\n",
        "\n",
        "    result = extract_meeting_summary(deepseek_model, tokenizer, cleaned_text, retry_attempts=3)\n",
        "\n",
        "    del deepseek_model\n",
        "    del tokenizer\n",
        "    gc.collect()  # Force garbage collection\n",
        "    torch.cuda.empty_cache()  # Free GPU memory\n",
        "    torch.cuda.ipc_collect()  # Collect GPU shared memory\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "c9q9twWAZO9l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Форматирование вывода для чтения"
      ],
      "metadata": {
        "id": "pgZm9iXqyIll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def format_transcription(text):\n",
        "    # Разбиваем текст по знакам окончания предложений (. ! ?), оставляя их в тексте\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+', text.strip())\n",
        "    # Выводим каждое предложение на новой строке\n",
        "    formatted_text = \"\\n\".join(sentences)\n",
        "    return formatted_text"
      ],
      "metadata": {
        "id": "SJnbjc1cyGUl"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "\n",
        "def clean_list(lst):\n",
        "    \"\"\"Очищает список от закодированных строковых списков, убирает дубликаты и лишние символы.\"\"\"\n",
        "    seen = set()\n",
        "    cleaned_list = []\n",
        "\n",
        "    for item in lst:\n",
        "        if isinstance(item, str):\n",
        "            item = item.strip().replace(\"«\", \"\").replace(\"»\", \"\")\n",
        "\n",
        "            # Проверяем, является ли item строковым списком (например, '[\"a\", \"b\"]')\n",
        "            if item.startswith(\"[\") and item.endswith(\"]\"):\n",
        "                try:\n",
        "                    parsed_item = ast.literal_eval(item)  # Преобразуем строку в список\n",
        "                    if isinstance(parsed_item, list):\n",
        "                        for sub_item in parsed_item:\n",
        "                            sub_item = str(sub_item).strip().replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "                            if sub_item and sub_item not in seen:\n",
        "                                cleaned_list.append(sub_item)\n",
        "                                seen.add(sub_item)\n",
        "                        continue  # Пропускаем добавление исходной строки\n",
        "                except (ValueError, SyntaxError):\n",
        "                    pass  # Если ошибка, рассматриваем как обычную строку\n",
        "\n",
        "        # Разбиваем по запятым, если в строке несколько пунктов\n",
        "        if \",\" in item:\n",
        "            sub_items = [x.strip() for x in item.split(\",\") if x.strip()]\n",
        "            for sub_item in sub_items:\n",
        "                if sub_item and sub_item not in seen:\n",
        "                    cleaned_list.append(sub_item)\n",
        "                    seen.add(sub_item)\n",
        "            continue  # Не добавляем исходную строку повторно\n",
        "\n",
        "        if item and item not in seen:\n",
        "            cleaned_list.append(item)\n",
        "            seen.add(item)\n",
        "\n",
        "    return cleaned_list\n",
        "\n",
        "def remove_duplicates(lst):\n",
        "    \"\"\"Удаляет дубликаты из списка, сохраняя порядок, с учётом пробелов и регистра.\"\"\"\n",
        "    seen = set()\n",
        "    cleaned = []\n",
        "    for x in lst:\n",
        "        cleaned_x = x.strip().lower()  # Приводим к нижнему регистру, убираем пробелы\n",
        "        if cleaned_x not in seen:\n",
        "            seen.add(cleaned_x)\n",
        "            cleaned.append(x.strip())  # Сохраняем оригинальный формат строки\n",
        "    return cleaned\n",
        "\n",
        "def clean_meeting_summary(meeting_info):\n",
        "    \"\"\"Очищает JSON-данные от дубликатов и вложенных списков.\"\"\"\n",
        "\n",
        "    # Очистка списков + удаление дубликатов\n",
        "    for key in [\"Topics\", \"Actions\", \"Problems\", \"Decisions\"]:\n",
        "        meeting_info[key] = remove_duplicates(clean_list(meeting_info.get(key, [])))\n",
        "\n",
        "    # Очистка резюме (по предложениям) с учётом пробелов и регистра\n",
        "    if \"Summarization\" in meeting_info:\n",
        "        sentences = [s.strip() for s in meeting_info[\"Summarization\"].split('.') if s.strip()]\n",
        "        meeting_info[\"Summarization\"] = '. '.join(remove_duplicates(sentences))\n",
        "\n",
        "    return meeting_info\n",
        "\n",
        "def format_meeting_info(meeting_info):\n",
        "    \"\"\"Форматирует JSON-данные в человекочитаемый текст.\"\"\"\n",
        "    summary_text = '\\n'.join(meeting_info.get('Summarization', '').split('. '))\n",
        "    formatted_text = f\"**Резюме встречи:**\\n{summary_text}\\n\\n\"\n",
        "\n",
        "    formatted_text += \"**Темы обсуждения:**\\n\"\n",
        "    topics = meeting_info.get('Topics', [])\n",
        "    formatted_text += \"\\n\".join(f\"- {topic}\" for topic in topics) + \"\\n\\n\" if topics else \"Нет тем.\\n\\n\"\n",
        "\n",
        "    formatted_text += \"**Действия:**\\n\"\n",
        "    actions = meeting_info.get('Actions', [])\n",
        "    formatted_text += \"\\n\".join(f\"- {action}\" for action in actions) + \"\\n\\n\" if actions else \"Нет действий.\\n\\n\"\n",
        "\n",
        "    formatted_text += \"**Проблемы:**\\n\"\n",
        "    problems = meeting_info.get('Problems', [])\n",
        "    formatted_text += \"\\n\".join(f\"- {problem}\" for problem in problems) + \"\\n\\n\" if problems else \"Нет проблем.\\n\\n\"\n",
        "\n",
        "    formatted_text += \"**Решения:**\\n\"\n",
        "    decisions = meeting_info.get('Decisions', [])\n",
        "    formatted_text += \"\\n\".join(f\"- {decision}\" for decision in decisions) + \"\\n\" if decisions else \"Нет решений.\\n\"\n",
        "\n",
        "    return formatted_text"
      ],
      "metadata": {
        "id": "eGh2rpb7yx83"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Получение транскрипции из видео и определение ключевой информации"
      ],
      "metadata": {
        "id": "-jJ8dCrFU4Cb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "DJe1xob5UlsA",
        "outputId": "d0737834-0045-4f23-c1d8-9119c1f179d2",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Аудио успешно извлечено: /content/drive/MyDrive/DP_outputs/extracted_audio.wav\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "[Errno 17] File exists: '/content/drive/MyDrive/DP_outputs/chunks'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-24482d4884a5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maudio_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvideo_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mchunk_paths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msplit_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-c986419bd66f>\u001b[0m in \u001b[0;36msplit_audio\u001b[0;34m(audio_path)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m# Load full audio file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mchunks_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/DP_outputs/chunks\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0maudio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Ensure 16kHz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0mchunk_duration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m  \u001b[0;31m# Split into 30-second chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/MyDrive/DP_outputs/chunks'"
          ]
        }
      ],
      "source": [
        "video_path = \"/content/drive/MyDrive/DP_datasets/GMT20240104_103040.mp4\"\n",
        "\n",
        "audio_path=extract_audio(video_path)\n",
        "\n",
        "chunk_paths=split_audio(audio_path)\n",
        "\n",
        "full_transcription=get_transcription(chunk_paths)\n",
        "\n",
        "meeting_info = get_meeting_info(full_transcription)\n",
        "\n",
        "cleaned_meeting_info = clean_meeting_summary(meeting_info)\n",
        "formatted_text = format_meeting_info(cleaned_meeting_info)\n",
        "\n",
        "print(\"\\n-----------------------------------------------------------------\")\n",
        "print(\"Транскрипция встречи\")\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(format_transcription(full_transcription))\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Ключевые моменты встречи\")\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(formatted_text)"
      ]
    }
  ]
}